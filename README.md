â­ Visual Voice â€“ AI-Powered Sign Language Detection
Real-time gesture recognition using deep learning, computer vision, and a fully interactive web interface.

ğŸ“Œ Overview

Visual Voice is an end-to-end AI system that detects sign language gestures using:

ğŸ“· Real-time webcam inference

ğŸ–¼ï¸ Image upload prediction

ğŸ¥ Automatic dataset collection via webcam

ğŸ§  Custom gesture training with CNN

ğŸŒ Beautiful Flask-based UI

It allows anyone to create, collect, train, and test custom gesture datasetsâ€”no ML expertise required.

ğŸš€ Features
ğŸ”¹ 1. Real-Time Gesture Detection

Uses your webcam to predict gestures live with confidence scores.

ğŸ”¹ 2. Upload & Predict

Upload a static gesture image and get instant predictions.

ğŸ”¹ 3. Automatic Dataset Collection

Collect gesture dataset using webcam with:

Auto-capture mode

Live ROI box

Organized dataset folders

ğŸ”¹ 4. Train Your Own Model

Train a CNN with your custom dataset using a single click.

ğŸ”¹ 5. View Last Prediction

Displays the most recent result from the prediction module.

ğŸ”¹ 6. Clean Modern UI

Bootstrap-powered card layout:

Live Detection

Upload Dataset

Upload Image

Train Model

View Last Prediction

ğŸ”¹ 7. Extendable Architecture

Add new gestures anytimeâ€”no rewriting required.

ğŸ“‚ Project Structure
VisualVoice/
â”‚â”€â”€ app.py
â”‚â”€â”€ collect_gestures.py
â”‚â”€â”€ model/
â”‚â”€â”€ dataset/
â”‚â”€â”€ static/
â”‚   â”œâ”€â”€ upload.jpg
â”‚   â””â”€â”€ styles.css
â”‚â”€â”€ templates/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ live.html
â”‚   â”œâ”€â”€ result.html
â”‚   â”œâ”€â”€ upload_dataset.html
â”‚   â””â”€â”€ static_prediction.html
â”‚â”€â”€ README.md

ğŸ§  Model

A lightweight CNN designed for speed and realtime accuracy:

Conv2D â†’ ReLU

MaxPooling

Conv2D â†’ ReLU

Flatten

Dense(128)

Dense(#labels) + Softmax

Trains in seconds on CPU.

ğŸ› ï¸ Installation & Setup
Clone Repository
git clone https://github.com/YourUsername/VisualVoice.git
cd VisualVoice

Create Virtual Environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

Install Dependencies
pip install -r requirements.txt

Run App
python app.py

ğŸ§ª Usage Workflow
1ï¸âƒ£ Add a New Gesture

Go to â†’ Upload New Gesture Dataset
â†’ Enter label name
â†’ Webcam opens and captures images automatically

2ï¸âƒ£ Train Model

Click Train Model
â†’ Model is saved to model/gesture_model.h5

3ï¸âƒ£ Predict

Use either:

Live Detection

Upload Image

4ï¸âƒ£ View Last Prediction

Shows the most recent static prediction image & result.
<img width="1875" height="919" alt="Screenshot 2025-12-01 020136" src="https://github.com/user-attachments/assets/0842bf23-2865-4fd5-a6df-9aebd5d6902d" />

<img width="975" height="699" alt="Screenshot 2025-12-01 020147" src="https://github.com/user-attachments/assets/ee6f55b9-5a9a-40e4-af6d-cc7f994f01a3" />
<img width="838" height="641" alt="Screenshot 2025-12-01 020326" src="https://github.com/user-attachments/assets/17ac4579-08ef-4a2d-babd-fbed450a0762" />
<img width="579" height="780" alt="Screenshot 2025-12-01 021411" src="https://github.com/user-attachments/assets/498dca70-6489-442b-82b9-dc720ef09dad" />




ğŸ”® Future Upgrades (Recommended Features)

Here are some great enhancements you can add:

ğŸ“Œ AI Features

Transformer-based gesture recognition

3D hand landmark detection (MediaPipe)

Multi-gesture sentences using sequence models

American Sign Language (ASL) alphabet mode

ğŸ“Œ UX / UI Features

Dark/Light theme switch

Dashboard analytics for dataset size

Gesture preview gallery

ğŸ“Œ Developer Features

REST API for gesture inference

WebSocket real-time streaming

Export model to ONNX / TFLite

Let me knowâ€”I can implement any of these.

ğŸ¤ Contributing

Pull requests are welcome.
For major changes, open an issue first to discuss what you'd like to improve.

ğŸ“ License

MIT License.

ğŸ’¡ Credits

Created by Dhruv
Built with â¤ï¸ using Python, Flask, TensorFlow & OpenCV.
